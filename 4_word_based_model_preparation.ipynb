{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "657db6d5-17d0-4811-9a01-cb012c63d6bf",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "id": "jehXeXNHmclc",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# 4. Word-Based Modelling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOfrhR-9bFfh"
   },
   "source": [
    "In this notebook, the lyrics are modified and prepared such that the language model can be trained. In order to do so, some further processing steps are needed as the model architecture works with numbers instead of words. Furthermore, some cleaning of the data will be done before that.<br><br>\n",
    "__Note:__ Training the model will be done in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-985082fc-d61d-4aca-812e-7b9c3c7e2211",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 4162,
     "status": "ok",
     "timestamp": 1663875368717,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "execution_millis": 3,
    "execution_start": 1656422208266,
    "id": "LL9i5KbCmclg",
    "outputId": "c6a0c021-a9b5-4abb-9511-a863945724c6",
    "source_hash": "b4788a64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import collections # to count frequency of tokens\n",
    "!pip install more_itertools # for splitting list into sublists\n",
    "from more_itertools import split_before \n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger') # for using default pos_tag\n",
    "nltk.download('universal_tagset') # for using pos_tag with tagset = \"universal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWp5wIbciPum"
   },
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qDegVYgBjjhY"
   },
   "outputs": [],
   "source": [
    "# load lyrics\n",
    "with open(\"./data/lyrics.txt\", encoding=\"utf-8\") as f:\n",
    "    lyrics = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1663661935501,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "2eWCC8ngo9Hb",
    "outputId": "64139a9b-f60c-434b-bcbd-2d36635a86e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49387903\n"
     ]
    }
   ],
   "source": [
    "# number of lines\n",
    "print(len(lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mH55kfavQ6-W"
   },
   "outputs": [],
   "source": [
    "# only take first 1000 lyrics\n",
    "#re.findall(\"<START>\", lyrics)\n",
    "# end = [string.start() for string in re.finditer(r\"<START>\" , lyrics)][1001]\n",
    "# lyrics = lyrics[0:end]\n",
    "# print(len(lyrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylcEOi5Sb2JH"
   },
   "source": [
    "In order to work with the lyrics, the songs should be split up into lists (tokenized). Furthermore, in order to reduce the number of words, all are turned into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M9UKK8xG9z3g"
   },
   "outputs": [],
   "source": [
    "# function to convert words into tokens and store each song in a separate list\n",
    "def tokenize(text: str):\n",
    "\n",
    "  # turn to all lowercase to reduce vocabulary size\n",
    "  text = text.lower()\n",
    "\n",
    "  # remove punctuation but keep <> for <START>\n",
    "  punctuation = \"\".join([punct for punct in string.punctuation if punct not in {\"<\", \">\", \"'\"}])\n",
    "  for punct in punctuation:\n",
    "      text = text.replace(punct, ' '+punct+' ')\n",
    "\n",
    "  # split by whitespace and newline, keep newline character\n",
    "  words = re.split(r\"( |\\n)\", text)\n",
    "\n",
    "  # remove whitespace from list\n",
    "  unwanted = {\"\", \" \"}\n",
    "  words = [elem for elem in words if elem not in unwanted]\n",
    "\n",
    "  # split list into sublists (1 list per song)\n",
    "  # there should be a strict separation between songs, ie. the last words from one\n",
    "  #  song should not be used to predict the first words from the next song\n",
    "  words = list(split_before(words, lambda x: x == \"<start>\"))\n",
    "\n",
    "  # remove <start> tag (= first token)\n",
    "  words = [song[1:] for song in words]\n",
    "\n",
    "  # remove \"\\n\" as first token from the songs\n",
    "  songs = []\n",
    "  for i, song in enumerate(words):\n",
    "    while song[0] == \"\\n\":\n",
    "      song = song[1:]\n",
    "    songs.append(song)\n",
    "  \n",
    "  # returns nested list (1 song = 1 list)\n",
    "  return(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNXceqmW-A3s"
   },
   "outputs": [],
   "source": [
    "words = tokenize(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1663661949302,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "0p-aT6pmLmb3",
    "outputId": "54dbb1ab-d998-49d2-bd0a-8cdb57e24c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there', \"ain't\", 'no', 'gold', 'in', 'this', 'river', '\\n', 'that', \"i've\", 'been', \"washin'\", 'my', 'hands', 'in', 'forever', '\\n', 'i', 'know', 'there', 'is', 'hope', 'in', 'these', 'waters', '\\n', 'but', 'i', \"can't\", 'bring', 'myself', 'to', 'swim', '\\n', 'when', 'i', 'am', 'drowning', 'in', 'this', 'silence', '\\n', 'baby', ',', 'let', 'me', 'in', '\\n', '\\n', 'go', 'easy', 'on', 'me', ',', 'baby', '\\n', 'i', 'was', 'still', 'a', 'child', '\\n', \"didn't\", 'get', 'the', 'chance', 'to', '\\n', 'feel', 'the', 'world', 'around', 'me', '\\n', 'i', 'had', 'no', 'time', 'to', 'choose', 'what', 'i', 'chose', 'to', 'do', '\\n', 'so', 'go', 'easy', 'on', 'me', '\\n', '\\n', 'there', \"ain't\", 'no', 'room', 'for', 'things', 'to', 'change', '\\n', 'when', 'we', 'are', 'both', 'so', 'deeply', 'stuck', 'in', 'our', 'ways', '\\n', 'you', \"can't\", 'deny', 'how', 'hard', 'i', 'have', 'tried', '\\n', 'i', 'changed', 'who', 'i', 'was', 'to', 'put', 'you', 'both', 'first', '\\n', 'but', 'now', 'i', 'give', 'up', '\\n', '\\n', 'go', 'easy', 'on', 'mе', ',', 'baby', '\\n', 'i', 'was', 'still', 'a', 'child', '\\n', \"didn't\", 'get', 'the', 'chance', 'to', '\\n', 'feel', 'thе', 'world', 'around', 'me', '\\n', 'had', 'no', 'time', 'to', 'choose', 'what', 'i', 'chose', 'to', 'do', '\\n', 'so', 'go', 'easy', 'on', 'me', '\\n', 'i', 'had', 'good', 'intentions', '\\n', 'and', 'the', 'highest', 'hopes', '\\n', 'but', 'i', 'know', 'right', 'now', '\\n', 'it', 'probably', \"doesn't\", 'even', 'show', '\\n', '\\n', 'go', 'easy', 'on', 'me', ',', 'baby', '\\n', 'i', 'was', 'still', 'a', 'child', '\\n', 'i', \"didn't\", 'get', 'the', 'chance', 'to', '\\n', 'feel', 'the', 'world', 'around', 'me', '\\n', 'i', 'had', 'no', 'time', 'to', 'choose', 'what', 'i', 'chose', 'to', 'do', '\\n', 'so', 'go', 'easy', 'on', 'me', '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1663661949303,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "491p46jHa8w_",
    "outputId": "f018499c-9e81-4ee1-eeed-dea2e6c3ad6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15496"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of songs\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HLWaaT-cQHp"
   },
   "source": [
    "Next, we count the occurences of each word to find words that occur only a few times. They will not be very useful for our model, as the model cannot really learn what follows after them when there are is only a little amount of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4L7JDcnzqUW"
   },
   "outputs": [],
   "source": [
    "# count words\n",
    "all_words = [x for xs in words for x in xs]\n",
    "c = collections.Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1663661951407,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "jE4N-1xR8xgG",
    "outputId": "abc3625f-56d0-46db-cf32-c749aa07b3d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['much', 'too', 'late', '\\n', 'and', 'you', 'deserve', 'someone', 'better', '\\n', '\\n', 'save', 'your', 'tears', 'for', 'another', 'day', '(', 'oh', 'yeah', ')', '\\n', 'save', 'your', 'tears', 'for', 'another', 'day', '(', 'yeah', ')', '\\n', '\\n', 'i', \"don't\", 'know', 'why', 'i', 'run', 'away', '\\n', \"i'll\", 'make', 'you', 'cry', 'when', 'i', 'run', 'away', '\\n', 'save', 'your', 'tears', 'for', 'another', 'day', '\\n', 'ooh', ',', 'girl', ',', 'i', 'said', '(', 'ah', ')', '\\n', 'save', 'your', 'tears', 'for', 'another', 'day', '(', 'ah', ')', '\\n', '\\n', 'save', 'your', 'tears', 'for', 'another', 'day', '(', 'ah', ')', '\\n', 'save', 'your', 'tears', 'for', 'another', 'day', '(', 'ah', ')', '\\n', 'i', \"wouldn't\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[10000:10100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1663661951407,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "wlaIqDPk21Ds",
    "outputId": "ef4bf5e6-31f6-4fde-95c7-6a2dfff3d44c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words before filter: 98557\n",
      "number of words after filter: 24990\n"
     ]
    }
   ],
   "source": [
    "# filter out uncommon words, s.t. only words that occur more than x times are kept\n",
    "MIN_OCCURENCE = 7\n",
    "dictionary = dict(c)\n",
    "print(\"number of words before filter: {}\".format(len(dictionary)))\n",
    "uncommon_words = sorted({k for k, v in dictionary.items() if v < MIN_OCCURENCE})\n",
    "dictionary = sorted({k for k, v in dictionary.items() if v >= MIN_OCCURENCE})\n",
    "print(\"number of words after filter: {}\".format(len(dictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1663661951407,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "aLwLwjsPkThB",
    "outputId": "7d8c2c05-b50a-49be-cf87-1238f62b2ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biddles', 'biddly', 'biddy’s', 'biden', 'bides', 'bidet', 'bidets', 'biding', 'bidness', 'bidou', 'biedermeyer', 'biennale', 'bienvenida', 'bienvenido', 'bienvenidos', 'bierhiven', 'biff', 'bifocal', 'bifurcated', \"big's\", 'bigalow', 'bigbagbone', 'bigboy', 'bigdud', 'bigfeet', 'bigga', \"biggavel'\", \"bigger's\", \"bigges'\", 'biggidy', \"biggie's\", 'biggies', 'biggie’s', 'biggin', \"biggin'\", 'bigging', 'biggio', 'biggish', 'biggity', 'biggood', \"biggs'\", 'biggy', 'biggz', 'bighead', 'bighorn', 'bight', 'bigness', 'bigot', 'bigotes', 'bigotry', 'bigots', 'bigrented', 'bigrob', 'bigslaps', 'bigsplash', 'biguidd', 'bigwig', 'bigwigs', 'big—', 'big’in', 'biitch', 'bijan', 'bikers', 'bikeygels', \"bikin'\", 'bil', \"bil'\", 'bilal', 'bilaws', 'bilbos', 'bile', 'bilge', 'biliary', 'biling', 'bilingual', 'bilious', 'bilive', 'bilks', \"bill'\", \"bill's\", 'billable', 'billers', 'billet', 'billets', 'billfold', 'billi', 'billiard', 'billiards', 'billies', 'billin', \"billin'\", 'billing', 'billington', 'billionaires', 'billions—what', 'billis', 'billot', 'billowed', 'billowing', 'billowy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncommon_words[8000:8100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling uncommon words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqU0esy-gR-J"
   },
   "source": [
    "Instead of deleting uncommon words, we replace them with their word-type, eg. noun, verb etc. With this, we don't have to omit sequences that contain these words and the model can still learn some basic sentence structure using them. This procedure is needed to **allow our model to work with user input that contains a word that is not in the dictionary** of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5905,
     "status": "ok",
     "timestamp": 1663661957309,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "OvHxq5uZkIYp",
    "outputId": "9f52c3b5-fa70-41eb-fb3c-c5a7687c905f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('biddles', 'NOUN'), ('biddly', 'ADV'), ('biddy’s', 'VERB'), ('biden', 'ADJ'), ('bides', 'NOUN'), ('bidet', 'VERB'), ('bidets', 'NOUN'), ('biding', 'VERB'), ('bidness', 'NOUN'), ('bidou', 'NOUN'), ('biedermeyer', 'NOUN'), ('biennale', 'NOUN'), ('bienvenida', 'NOUN'), ('bienvenido', 'NOUN'), ('bienvenidos', 'VERB'), ('bierhiven', 'ADV'), ('biff', 'ADJ'), ('bifocal', 'ADJ'), ('bifurcated', 'VERB'), (\"big's\", 'NOUN'), ('bigalow', 'ADP'), ('bigbagbone', 'NOUN'), ('bigboy', 'NOUN'), ('bigdud', 'NOUN'), ('bigfeet', 'NOUN'), ('bigga', 'NOUN'), (\"biggavel'\", 'NOUN'), (\"bigger's\", 'NOUN'), (\"bigges'\", 'NOUN'), ('biggidy', 'NOUN'), (\"biggie's\", 'NOUN'), ('biggies', 'NOUN'), ('biggie’s', 'VERB'), ('biggin', 'NOUN'), (\"biggin'\", 'NOUN'), ('bigging', 'VERB'), ('biggio', 'ADJ'), ('biggish', 'ADJ'), ('biggity', 'NOUN'), ('biggood', 'NOUN'), (\"biggs'\", 'NOUN'), ('biggy', 'NOUN'), ('biggz', 'NOUN'), ('bighead', 'NOUN'), ('bighorn', 'VERB'), ('bight', 'ADJ'), ('bigness', 'NOUN'), ('bigot', 'VERB'), ('bigotes', 'NOUN'), ('bigotry', 'VERB'), ('bigots', 'NOUN'), ('bigrented', 'VERB'), ('bigrob', 'ADJ'), ('bigslaps', 'NOUN'), ('bigsplash', 'VERB'), ('biguidd', 'NOUN'), ('bigwig', 'NOUN'), ('bigwigs', 'NOUN'), ('big—', 'VERB'), ('big’in', 'ADJ'), ('biitch', 'NOUN'), ('bijan', 'NOUN'), ('bikers', 'NOUN'), ('bikeygels', 'VERB'), (\"bikin'\", 'NOUN'), ('bil', 'NOUN'), (\"bil'\", 'NOUN'), ('bilal', 'NOUN'), ('bilaws', 'NOUN'), ('bilbos', 'NOUN'), ('bile', 'ADP'), ('bilge', 'NOUN'), ('biliary', 'ADJ'), ('biling', 'VERB'), ('bilingual', 'ADJ'), ('bilious', 'ADJ'), ('bilive', 'ADJ'), ('bilks', 'NOUN'), (\"bill'\", 'VERB'), (\"bill's\", 'NOUN'), ('billable', 'ADJ'), ('billers', 'NOUN'), ('billet', 'VERB'), ('billets', 'NOUN'), ('billfold', 'VERB'), ('billi', 'ADJ'), ('billiard', 'NOUN'), ('billiards', 'NOUN'), ('billies', 'NOUN'), ('billin', 'VERB'), (\"billin'\", 'ADP'), ('billing', 'VERB'), ('billington', 'NOUN'), ('billionaires', 'NOUN'), ('billions—what', 'ADP'), ('billis', 'NOUN'), ('billot', 'NOUN'), ('billowed', 'VERB'), ('billowing', 'VERB'), ('billowy', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "# get POS tag of uncommon words (ie. if it's a noun, verb etc.)\n",
    "# replace uncommon word with it's tag\n",
    "pos = nltk.pos_tag(uncommon_words, tagset = \"universal\")\n",
    "print(pos[8000:8100])\n",
    "# consider using tagset = \"universal\" which only returns NOUN, ADJ etc.\n",
    "# only keep tags\n",
    "pos = [\"<\" + tag + \">\" for (word, tag) in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1663875405379,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "SheLxlGSnw0N",
    "outputId": "69c51ddd-c1ed-46eb-979c-b2af68f19c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lumos', 'NOUN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"Lumos\"], tagset = \"universal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1663875545552,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "W5_FAuN5s9tz",
    "outputId": "a01d36eb-5fd6-4590-c553-2061c5ee2734"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wait', 'NOUN'), ('until', 'ADP')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"wait\",\"until\"], tagset = \"universal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1663661957310,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "cFdoKVMCo3zd",
    "outputId": "6fe08bde-5673-4c97-d7c6-edb552544967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<.>', '<ADJ>', '<ADP>', '<ADV>', '<CONJ>', '<DET>', '<NOUN>',\n",
       "       '<NUM>', '<PRON>', '<PRT>', '<VERB>', '<X>'], dtype='<U6')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 12 tag-types\n",
    "np.unique(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1KpJjwGqBYJ"
   },
   "outputs": [],
   "source": [
    "# create dictionary of uncommon word : tag\n",
    "pos_dict = dict(zip(uncommon_words, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsQRm0ufpIYw"
   },
   "outputs": [],
   "source": [
    "# add tags to dictionary\n",
    "dictionary.extend(np.unique(pos))\n",
    "# dictionary[len(dictionary) - 13:len(dictionary) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1663661959233,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "MkRlca_wq3_G",
    "outputId": "149e785a-37df-4680-d66a-5bd2c080f5d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaced words: 151972\n"
     ]
    }
   ],
   "source": [
    "# replace uncommon words with their tags\n",
    "count_replaced = 0\n",
    "for i, song in enumerate(words):\n",
    "  for j, word in enumerate(song):\n",
    "    if word in pos_dict:\n",
    "      #print((i,j, word))\n",
    "      #print(words[i][j])\n",
    "      words[i][j] = pos_dict[word]\n",
    "      count_replaced += 1\n",
    "print(\"replaced words:\", count_replaced)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1663661959578,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "MkhmCb4qCNv_",
    "outputId": "1845f9bd-9c0a-4fd6-9a33-5013a46fa8f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 984638), (',', 613673), ('the', 319020), ('i', 259627), ('you', 245381), ('to', 178527), ('and', 178509), ('a', 165695), ('.', 130654), (')', 124164)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in our trainings lyrics\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionaries for switching between numeric and real representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hl4ousHglWk"
   },
   "source": [
    "An important step is to create two dictionaries. One that maps a word to it's numerical representation (index) and one that does it the other way around. Using them, we can switch between representations and train the model on numerical data which can then later be changed back to the actual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-6f7184f9-6504-402f-b0db-5528bc0f553b",
    "deepnote_cell_height": 171,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1656422209318,
    "id": "H_MTimOymclm",
    "source_hash": "7382f4fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define two dictionaries for mapping words to numbers and back\n",
    "word_to_index = dict((c, i) for i, c in enumerate(dictionary))\n",
    "index_to_word = dict((i, c) for i, c in enumerate(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-e52859f2-8577-4380-9be1-356cbf4b40fb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 708,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1663661959580,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "execution_millis": 5,
    "execution_start": 1656422209323,
    "id": "tQFtOnMEmclm",
    "outputId": "cbb9d3ca-2264-4055-e909-dfd253402232",
    "source_hash": "502c6875",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '\\n'), (1, '!'), (2, '\"'), (3, '$'), (4, '%'), (5, '&'), (6, \"'\"), (7, \"'03\"), (8, \"'09\"), (9, \"'42\"), (10, \"'64\"), (11, \"'65\"), (12, \"'69\"), (13, \"'70s\"), (14, \"'80s\"), (15, \"'87\"), (16, \"'88\"), (17, \"'89\"), (18, \"'90s\"), (19, \"'92\")]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index_to_word.items())[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into predictor / target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4u9ZHRJ2c4-n"
   },
   "source": [
    "The model works with sequential data (our song lyrics). It takes a sequence of fixed size (eg. 5 words / tokens) to predict the next word. For example:<br><br>\n",
    "['there', \"ain't\", 'no', 'gold', 'in'] -> ['this']<br>\n",
    "[\"ain't\", 'no', 'gold', 'in', 'this'] -> ['river']<br><br>\n",
    "and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCDldnmucieZ"
   },
   "source": [
    "In order to determine which sequence length the model should be trained on (eg. how long should the sequence be that can predict the next word?), the average distance between newline characters is calculated, which corresponds to the average length of lines in the song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1663661960872,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "KYTHtSU59Det",
    "outputId": "d12faaf5-32a8-4516-877c-3fb40467f95f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7214, 5648, 5506, ...,    1,    1,    1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find average distance between newline characters to determine optimal Sequence Length\n",
    "# = average length of lines in lyrics\n",
    "positions = [i for i, x in enumerate(all_words) if x == \"\\n\"]\n",
    "\n",
    "diff = np.diff(positions)\n",
    "# sort from high to low\n",
    "diff[::-1].sort()\n",
    "# some huge outliers on the higher end\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1663661961428,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "9J-vJnSR-QOw",
    "outputId": "6ead8b13-2347-4684-995d-ba18f922988c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYAklEQVR4nO3dfaxddZ3v8fdnWkAyjpaHcwlpe28ZbWIquVbtYCeaGwciFDBTTNALmSuNaawTS65mvDMU/8EnEvhDmSFREpQOxTjWBvXSaJ1OAyTe+YOHg1agoOEMD6FNpWdoAY0RA37vH/tX3Rz2Ouf0ae9TeL+Snb3Wd/3WWt+9AvvTvdba+6SqkCRpkD8ZdQOSpLnLkJAkdTIkJEmdDAlJUidDQpLUaf6oGzjaTj/99FqyZMmo25Ck48oDDzzwn1U1NrU+65BIMg8YB/ZU1QeTnAVsBk4DHgA+WlW/S3IScBvwbuBZ4H9W1ZNtG1cDa4GXgf9dVdtbfRXwT8A84BtVdV2rD9zHdH0uWbKE8fHx2b4sSRKQ5KlB9UM53fQp4NG++euBG6rqrcABem/+tOcDrX5DG0eSZcBlwNuBVcDXksxr4fNV4EJgGXB5GzvdPiRJQzCrkEiyCLgY+EabD3AucHsbsgm4pE2vbvO05ee18auBzVX1YlU9AUwA57THRFU93j4lbAZWz7APSdIQzPaTxD8C/wD8vs2fBjxXVS+1+d3Awja9EHgaoC1/vo3/Q33KOl316fbxCknWJRlPMj45OTnLlyRJmsmMIZHkg8C+qnpgCP0clqq6uapWVNWKsbFXXXeRJB2m2Vy4fi/w10kuAt4AvIneReYFSea3f+kvAva08XuAxcDuJPOBN9O7gH2wflD/OoPqz06zD0nSEMz4SaKqrq6qRVW1hN6F57uq6m+Au4FL27A1wB1temubpy2/q3q/IrgVuCzJSe2upaXAfcD9wNIkZyU5se1ja1unax+SpCE4ki/TXQX8XZIJetcPbmn1W4DTWv3vgA0AVbUL2AI8AvwrsL6qXm6fEq4EttO7e2pLGzvdPiRJQ5DX2k+Fr1ixovyehCQdmiQPVNWKqXV/lkOS1Ok197Mcx6slG344kv0+ed3FI9mvpOODnyQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdZoxJJK8Icl9SX6WZFeSz7f6rUmeSLKzPZa3epLcmGQiyYNJ3tW3rTVJHmuPNX31dyd5qK1zY5K0+qlJdrTxO5KccvQPgSSpy2w+SbwInFtV7wCWA6uSrGzL/r6qlrfHzla7EFjaHuuAm6D3hg9cA7wHOAe4pu9N/ybg433rrWr1DcCdVbUUuLPNS5KGZMaQqJ5ft9kT2qOmWWU1cFtb7x5gQZIzgQuAHVW1v6oOADvoBc6ZwJuq6p6qKuA24JK+bW1q05v66pKkIZjVNYkk85LsBPbRe6O/ty26tp1SuiHJSa22EHi6b/XdrTZdffeAOsAZVbW3Tf8SOKOjv3VJxpOMT05OzuYlSZJmYVYhUVUvV9VyYBFwTpKzgauBtwF/AZwKXHXMuuz1UHR8gqmqm6tqRVWtGBsbO5ZtSNLryiHd3VRVzwF3A6uqam87pfQi8M/0rjMA7AEW9622qNWmqy8aUAd4pp2Ooj3vO5R+JUlHZjZ3N40lWdCmTwY+APy878079K4VPNxW2Qpc0e5yWgk8304ZbQfOT3JKu2B9PrC9LXshycq2rSuAO/q2dfAuqDV9dUnSEMyfxZgzgU1J5tELlS1V9YMkdyUZAwLsBP62jd8GXARMAL8BPgZQVfuTfBG4v437QlXtb9OfBG4FTgZ+1B4A1wFbkqwFngI+crgvVJJ06GYMiap6EHjngPq5HeMLWN+xbCOwcUB9HDh7QP1Z4LyZepQkHRt+41qS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdZoxJJK8Icl9SX6WZFeSz7f6WUnuTTKR5DtJTmz1k9r8RFu+pG9bV7f6L5Jc0Fdf1WoTSTb01QfuQ5I0HLP5JPEicG5VvQNYDqxKshK4Hrihqt4KHADWtvFrgQOtfkMbR5JlwGXA24FVwNeSzEsyD/gqcCGwDLi8jWWafUiShmDGkKieX7fZE9qjgHOB21t9E3BJm17d5mnLz0uSVt9cVS9W1RPABHBOe0xU1eNV9TtgM7C6rdO1D0nSEMzqmkT7F/9OYB+wA/gP4LmqeqkN2Q0sbNMLgacB2vLngdP661PW6aqfNs0+pva3Lsl4kvHJycnZvCRJ0izMKiSq6uWqWg4sovcv/7cd064OUVXdXFUrqmrF2NjYqNuRpNeMQ7q7qaqeA+4G/hJYkGR+W7QI2NOm9wCLAdryNwPP9tenrNNVf3aafUiShmA2dzeNJVnQpk8GPgA8Si8sLm3D1gB3tOmtbZ62/K6qqla/rN39dBawFLgPuB9Y2u5kOpHexe2tbZ2ufUiShmD+zEM4E9jU7kL6E2BLVf0gySPA5iRfAn4K3NLG3wJ8M8kEsJ/emz5VtSvJFuAR4CVgfVW9DJDkSmA7MA/YWFW72rau6tiHJGkIZgyJqnoQeOeA+uP0rk9Mrf8W+HDHtq4Frh1Q3wZsm+0+JEnD4TeuJUmdDAlJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUqfZ/D0JvYYt2fDDkez3yesuHsl+JR0aP0lIkjoZEpKkTrP5G9eLk9yd5JEku5J8qtU/l2RPkp3tcVHfOlcnmUjyiyQX9NVXtdpEkg199bOS3Nvq32l/65r297C/0+r3JllyNF+8JGl6s/kk8RLwmapaBqwE1idZ1pbdUFXL22MbQFt2GfB2YBXwtSTz2t/I/ipwIbAMuLxvO9e3bb0VOACsbfW1wIFWv6GNkyQNyYwhUVV7q+onbfpXwKPAwmlWWQ1srqoXq+oJYILe36k+B5ioqser6nfAZmB1kgDnAre39TcBl/Rta1Obvh04r42XJA3BIV2TaKd73gnc20pXJnkwycYkp7TaQuDpvtV2t1pX/TTguap6aUr9Fdtqy59v46f2tS7JeJLxycnJQ3lJkqRpzDokkrwR+C7w6ap6AbgJeAuwHNgLfPmYdDgLVXVzVa2oqhVjY2OjakOSXnNmFRJJTqAXEN+qqu8BVNUzVfVyVf0e+Dq900kAe4DFfasvarWu+rPAgiTzp9Rfsa22/M1tvCRpCGZzd1OAW4BHq+orffUz+4Z9CHi4TW8FLmt3Jp0FLAXuA+4HlrY7mU6kd3F7a1UVcDdwaVt/DXBH37bWtOlLgbvaeEnSEMzmG9fvBT4KPJRkZ6t9lt7dScuBAp4EPgFQVbuSbAEeoXdn1PqqehkgyZXAdmAesLGqdrXtXQVsTvIl4Kf0Qon2/M0kE8B+esEiSRqSGUOiqv4dGHRH0bZp1rkWuHZAfdug9arqcf54uqq//lvgwzP1KEk6NvzGtSSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqNGNIJFmc5O4kjyTZleRTrX5qkh1JHmvPp7R6ktyYZCLJg0ne1betNW38Y0nW9NXfneShts6NSTLdPiRJwzGbTxIvAZ+pqmXASmB9kmXABuDOqloK3NnmAS4ElrbHOuAm6L3hA9cA76H396yv6XvTvwn4eN96q1q9ax+SpCGYMSSqam9V/aRN/wp4FFgIrAY2tWGbgEva9Grgtuq5B1iQ5EzgAmBHVe2vqgPADmBVW/amqrqnqgq4bcq2Bu1DkjQEh3RNIskS4J3AvcAZVbW3LfolcEabXgg83bfa7labrr57QJ1p9jG1r3VJxpOMT05OHspLkiRNY9YhkeSNwHeBT1fVC/3L2ieAOsq9vcJ0+6iqm6tqRVWtGBsbO5ZtSNLryqxCIskJ9ALiW1X1vVZ+pp0qoj3va/U9wOK+1Re12nT1RQPq0+1DkjQEs7m7KcAtwKNV9ZW+RVuBg3corQHu6Ktf0e5yWgk8304ZbQfOT3JKu2B9PrC9LXshycq2ryumbGvQPiRJQzB/FmPeC3wUeCjJzlb7LHAdsCXJWuAp4CNt2TbgImAC+A3wMYCq2p/ki8D9bdwXqmp/m/4kcCtwMvCj9mCafUiShmDGkKiqfwfSsfi8AeMLWN+xrY3AxgH1ceDsAfVnB+1DkjQcfuNaktTJkJAkdTIkJEmdDAlJUidDQpLUyZCQJHUyJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUidDQpLUyZCQJHWaMSSSbEyyL8nDfbXPJdmTZGd7XNS37OokE0l+keSCvvqqVptIsqGvflaSe1v9O0lObPWT2vxEW77kaL1oSdLszOaTxK3AqgH1G6pqeXtsA0iyDLgMeHtb52tJ5iWZB3wVuBBYBlzexgJc37b1VuAAsLbV1wIHWv2GNk6SNEQzhkRV/RjYP8vtrQY2V9WLVfUEMAGc0x4TVfV4Vf0O2AysThLgXOD2tv4m4JK+bW1q07cD57XxkqQhOZJrElcmebCdjjql1RYCT/eN2d1qXfXTgOeq6qUp9Vdsqy1/vo1/lSTrkownGZ+cnDyClyRJ6ne4IXET8BZgObAX+PJR6+gwVNXNVbWiqlaMjY2NshVJek05rJCoqmeq6uWq+j3wdXqnkwD2AIv7hi5qta76s8CCJPOn1F+xrbb8zW28JGlIDiskkpzZN/sh4OCdT1uBy9qdSWcBS4H7gPuBpe1OphPpXdzeWlUF3A1c2tZfA9zRt601bfpS4K42XpI0JPNnGpDk28D7gdOT7AauAd6fZDlQwJPAJwCqaleSLcAjwEvA+qp6uW3nSmA7MA/YWFW72i6uAjYn+RLwU+CWVr8F+GaSCXoXzi874lcrSTokM4ZEVV0+oHzLgNrB8dcC1w6obwO2Dag/zh9PV/XXfwt8eKb+JEnHzowh8XqyZMMPR92CJM0p/iyHJKmTISFJ6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE4zhkSSjUn2JXm4r3Zqkh1JHmvPp7R6ktyYZCLJg0ne1bfOmjb+sSRr+urvTvJQW+fGJJluH5Kk4ZnNJ4lbgVVTahuAO6tqKXBnmwe4EFjaHuuAm6D3hk/vb2O/h96fKr2m703/JuDjfeutmmEfkqQhmTEkqurHwP4p5dXApja9Cbikr35b9dwDLEhyJnABsKOq9lfVAWAHsKote1NV3VNVBdw2ZVuD9iFJGpLDvSZxRlXtbdO/BM5o0wuBp/vG7W616eq7B9Sn28erJFmXZDzJ+OTk5GG8HEnSIEd84bp9Aqij0Mth76Oqbq6qFVW1Ymxs7Fi2IkmvK4cbEs+0U0W0532tvgdY3DduUatNV180oD7dPiRJQ3K4IbEVOHiH0hrgjr76Fe0up5XA8+2U0Xbg/CSntAvW5wPb27IXkqxsdzVdMWVbg/YhSRqS+TMNSPJt4P3A6Ul207tL6TpgS5K1wFPAR9rwbcBFwATwG+BjAFW1P8kXgfvbuC9U1cGL4Z+kdwfVycCP2oNp9iFJGpIZQ6KqLu9YdN6AsQWs79jORmDjgPo4cPaA+rOD9iFJGh6/cS1J6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOs14C6x0LCzZ8MOR7fvJ6y4e2b6l442fJCRJnQwJSVInQ0KS1MmQkCR1MiQkSZ0MCUlSJ0NCktTJkJAkdTIkJEmdDAlJUidDQpLU6YhCIsmTSR5KsjPJeKudmmRHksfa8ymtniQ3JplI8mCSd/VtZ00b/1iSNX31d7ftT7R1cyT9SpIOzdH4JPFXVbW8qla0+Q3AnVW1FLizzQNcCCxtj3XATdALFeAa4D3AOcA1B4Oljfl433qrjkK/kqRZOhanm1YDm9r0JuCSvvpt1XMPsCDJmcAFwI6q2l9VB4AdwKq27E1VdU9VFXBb37YkSUNwpCFRwL8leSDJulY7o6r2tulfAme06YXA033r7m616eq7B9RfJcm6JONJxicnJ4/k9UiS+hzp35N4X1XtSfJfgB1Jft6/sKoqSR3hPmZUVTcDNwOsWLHimO9Pkl4vjuiTRFXtac/7gO/Tu6bwTDtVRHve14bvARb3rb6o1aarLxpQlyQNyWGHRJI/TfJnB6eB84GHga3AwTuU1gB3tOmtwBXtLqeVwPPttNR24Pwkp7QL1ucD29uyF5KsbHc1XdG3LUnSEBzJ6aYzgO+3u1LnA/9SVf+a5H5gS5K1wFPAR9r4bcBFwATwG+BjAFW1P8kXgfvbuC9U1f42/UngVuBk4EftIUkaksMOiap6HHjHgPqzwHkD6gWs79jWRmDjgPo4cPbh9ihJOjJ+41qS1MmQkCR1MiQkSZ0MCUlSJ0NCktTpSL9xLR13lmz44Uj2++R1F49kv9KR8JOEJKmTISFJ6mRISJI6GRKSpE6GhCSpkyEhSepkSEiSOhkSkqROhoQkqZMhIUnqZEhIkjr5203SkIzqN6PA343S4ZvznySSrEryiyQTSTaMuh9Jej2Z0yGRZB7wVeBCYBlweZJlo+1Kkl4/5vrppnOAiap6HCDJZmA18MhIu5KOM6M81aXhORanFed6SCwEnu6b3w28Z+qgJOuAdW3210l+MYTeDtfpwH+OuokZ2OPRYY9Hx/HQI8yBPnP9jEOm6/G/DSrO9ZCYlaq6Gbh51H3MRpLxqlox6j6mY49Hhz0eHcdDj3B89Hk4Pc7paxLAHmBx3/yiVpMkDcFcD4n7gaVJzkpyInAZsHXEPUnS68acPt1UVS8luRLYDswDNlbVrhG3daSOh9Ni9nh02OPRcTz0CMdHn4fcY6rqWDQiSXoNmOunmyRJI2RISJI6GRJDkuTJJA8l2ZlkfNT9HJRkY5J9SR7uq52aZEeSx9rzKXOwx88l2dOO584kF424x8VJ7k7ySJJdST7V6nPmWE7T45w5lknekOS+JD9rPX6+1c9Kcm/7eZ7vtBtZ5lqPtyZ5ou84Lh9Vj329zkvy0yQ/aPOHfBwNieH6q6paPsfupb4VWDWltgG4s6qWAne2+VG6lVf3CHBDO57Lq2rbkHua6iXgM1W1DFgJrG8/ITOXjmVXjzB3juWLwLlV9Q5gObAqyUrg+tbjW4EDwNo52CPA3/cdx52ja/EPPgU82jd/yMfRkHidq6ofA/unlFcDm9r0JuCSoTY1RUePc0pV7a2qn7TpX9H7H3Mhc+hYTtPjnFE9v26zJ7RHAecCt7f6qI9jV49zSpJFwMXAN9p8OIzjaEgMTwH/luSB9jMic9kZVbW3Tf8SOGOUzUzjyiQPttNRIz0l1i/JEuCdwL3M0WM5pUeYQ8eynSLZCewDdgD/ATxXVS+1IbsZcbhN7bGqDh7Ha9txvCHJSSNsEeAfgX8Aft/mT+MwjqMhMTzvq6p30ftF2/VJ/seoG5qN6t0jPef+lQTcBLyF3sf9vcCXR9tOT5I3At8FPl1VL/QvmyvHckCPc+pYVtXLVbWc3i8snAO8bZT9DDK1xyRnA1fT6/UvgFOBq0bVX5IPAvuq6oEj3ZYhMSRVtac97wO+T+8//rnqmSRnArTnfSPu51Wq6pn2P+rvga8zB45nkhPovfl+q6q+18pz6lgO6nEuHkuAqnoOuBv4S2BBkoNf/p0zP8/T1+OqdjqvqupF4J8Z7XF8L/DXSZ4ENtM7zfRPHMZxNCSGIMmfJvmzg9PA+cDD0681UluBNW16DXDHCHsZ6OAbb/MhRnw82/neW4BHq+orfYvmzLHs6nEuHcskY0kWtOmTgQ/Qu3ZyN3BpGzbq4ziox5/3/WMg9M71j+w4VtXVVbWoqpbQ+zmju6rqbziM4+g3rocgyZ/T+/QAvZ9C+ZequnaELf1Bkm8D76f3E8LPANcA/xfYAvxX4CngI1U1sgvHHT2+n97pkQKeBD7Rd+5/6JK8D/h/wEP88RzwZ+md858Tx3KaHi9njhzLJP+d3gXVefT+Ebulqr7Q/h/aTO80zk+B/9X+xT6XerwLGAMC7AT+tu8C98gkeT/wf6rqg4dzHA0JSVInTzdJkjoZEpKkToaEJKmTISFJ6mRISJI6GRKSpE6GhCSp0/8H5FW3cnGXH4YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# treat high values and newline characters that follow each other as outliers\n",
    "plt.hist(diff[(diff > 1) & (diff < 40)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1663661961428,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "TLV8D7lO9w_R",
    "outputId": "d3b8a76d-ee55-438b-84e6-4431767fe36b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.331346001383288"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average lenght of line\n",
    "np.mean(diff[(diff > 1) & (diff < 40)])\n",
    "# ~ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM56l_krg8Gx"
   },
   "source": [
    "Next, we need to create the training data. As described before, it consists of sequences of a certain length as the X-data, and the following word as the Y-data. In order to not predict the first word of the next song by the last words of the previous song, we have created a nested list of lyrics which allows us to stop at the last word for each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nELrsnT5JZCJ"
   },
   "outputs": [],
   "source": [
    "# make sequences for every song seperately\n",
    "# take sequence lenght corresponding to the average line length in our dataset to provide more context\n",
    "SEQ_LENGTH = 10\n",
    "\n",
    "# sequences will be the predictor data and next_word the target\n",
    "sequences = []\n",
    "next_word = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clxLaZMtKGnx"
   },
   "outputs": [],
   "source": [
    "# number of songs\n",
    "N_SONGS = len(words)\n",
    "\n",
    "# number of tokens in each song (words)\n",
    "song_lengths = [len(x) for x in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1663661961430,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "LoTlWnB_LMvl",
    "outputId": "03b23e3e-4bf5-46c4-8af6-18bd14e4f970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[249, 541, 791, 565, 501, 863, 650, 533, 807, 741]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_lengths[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40286,
     "status": "ok",
     "timestamp": 1663662001710,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "acnm-xDBKiKl",
    "outputId": "9e82c640-1cc5-4b18-da05-47444f979311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 10315059\n",
      "Ignored sequences: 0\n"
     ]
    }
   ],
   "source": [
    "# loop over data to create context for the prediction (next word)\n",
    "# NOTE: Also included is code that would ignore sequences which contain uncommon words\n",
    "# BUT: uncommon words were above treated differently (replaced by tag)\n",
    "# code is kept in case we switch back to this approach\n",
    "uncommon = set(uncommon_words)\n",
    "count_ignored = 0\n",
    "\n",
    "# loop over every song\n",
    "for song in range(0, N_SONGS):\n",
    "\n",
    "  # for every song create sequences of x words plus the next one until the length of the song\n",
    "  for word in range(0, song_lengths[song] - SEQ_LENGTH - 1):\n",
    "\n",
    "    # take sentence of length SEQ_LENGTH + 1 (also take the next word)\n",
    "    sentence = words[song][word: word + SEQ_LENGTH + 1]\n",
    "\n",
    "    # if sentence has one of the uncommon words, skip it\n",
    "    if len(set(sentence).intersection(uncommon)) == 0: \n",
    "      sequences.append(sentence[0:SEQ_LENGTH])\n",
    "      next_word.append(sentence[SEQ_LENGTH])\n",
    "      #next_word.append(words[song][word + SEQ_LENGTH])\n",
    "    else:\n",
    "      count_ignored += 1\n",
    "\n",
    "print(\"Number of sequences:\", len(sequences))\n",
    "print(\"Ignored sequences:\", count_ignored) # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1663662001710,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "y-IUxN_icsz2",
    "outputId": "817548f2-4cdf-4831-f18b-530313181ecd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hah', '\\n', 'but', 'these', 'niggas', 'bitches', 'like', '<NOUN>', ',', 'yeah'], ['\\n', 'but', 'these', 'niggas', 'bitches', 'like', '<NOUN>', ',', 'yeah', ',']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[1000:1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1663662001710,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "4xGKdw6WexPC",
    "outputId": "97f55e49-5a5c-4360-943a-102e941e5ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', 'yeah']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word[1000:1002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1-JDqOEhliu"
   },
   "source": [
    "Now we turn to numerical representation by using our word_to_index dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cma3glk5lfus"
   },
   "outputs": [],
   "source": [
    "x_vector = []\n",
    "y_vector = []\n",
    "\n",
    "# turn to numerical representation\n",
    "for seq in range(0, len(sequences)):\n",
    "  single_seq = []\n",
    "  for word in sequences[seq]:\n",
    "    single_seq.append(word_to_index[word])\n",
    "  \n",
    "  x_vector.append(single_seq)\n",
    "  y_vector.append(word_to_index[next_word[seq]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1663662045902,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "NPGrkBtFgKWI",
    "outputId": "2bdf2fb4-9684-45ac-fe8a-ce5cfb3b54bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10315059"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663662045902,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "uJ0gKT3nntgU",
    "outputId": "c29b7a92-40da-4924-a4b0-475e41dd632b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10315059"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1663662045902,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "2tq8kMKVgA6I",
    "outputId": "2d68dae7-347a-4a81-ba3b-4f8086c8205d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11621, 24302, 2045, 7111, 14895, 22208, 14007, 24553, 0, 24212], [24302, 2045, 7111, 14895, 22208, 14007, 24553, 0, 24212, 477]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vector[10000:10002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1663662045903,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "jbaS7DIm89m2",
    "outputId": "862e9cae-e40b-48b3-8568-d30d9f94c91f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[477, 23992]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vector[10000:10002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGAkrQEWhuWg"
   },
   "source": [
    "As the data is quite large (more than 10 million sequences and several tens of thousands of unique words), we create a Data Generator that allows us to create batches of data. See here: https://github.com/klaudia-nazarko/nlg-text-generation/blob/main/LSTM_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0P7z7hc9r3-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DW891WiT9kd2"
   },
   "outputs": [],
   "source": [
    "# create class for fitting to a sequence of data\n",
    "# useful for multiprocessing\n",
    "class TextDataGenerator(Sequence):\n",
    "    def __init__(self, sequences, next_words, sequence_length, vocab_size, batch_size=32, shuffle=True, embedding=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.sequences = sequences\n",
    "        self.next_words = next_words\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.shuffle = shuffle\n",
    "        self.embedding = embedding\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # must be implemented for class Sequence\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.sequences) / self.batch_size))\n",
    "\n",
    "    # must be implemented for class Sequence, gets batch at position index\n",
    "    def __getitem__(self, index):\n",
    "        # take sample of indexes, length = batch_size\n",
    "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # store relevant x and y data\n",
    "        sequences_batch = [self.sequences[k] for k in indexes]\n",
    "        next_words_batch = [self.next_words[k] for k in indexes]\n",
    "\n",
    "        if self.embedding:\n",
    "          X = np.array(sequences_batch)\n",
    "          y = keras.utils.to_categorical(next_words_batch, num_classes=self.vocab_size)\n",
    "        else:\n",
    "          X, y = self.__data_generation(sequences_batch, next_words_batch)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.sequences)) # vector of length len(x_data)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, sequences_batch, next_words_batch):\n",
    "        # create empty, 3 dimensional matrices\n",
    "        X = np.zeros((self.batch_size, self.sequence_length, self.vocab_size), dtype=bool)\n",
    "        y = np.zeros((self.batch_size, self.vocab_size), dtype=bool)\n",
    "\n",
    "        # fill matrices with 1 at the position of the word, essentially one-hot encoding\n",
    "        for i, seq in enumerate(sequences_batch):\n",
    "            for j, word in enumerate(seq):\n",
    "                X[i, j, word] = 1\n",
    "                y[i, next_words_batch[i]] = 1\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_JTTsIi91Nr"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(dictionary)\n",
    "\n",
    "params = {\n",
    "  'sequence_length': SEQ_LENGTH,\n",
    "  'vocab_size': VOCAB_SIZE,\n",
    "  'batch_size': BATCH_SIZE,\n",
    "  'shuffle': True\n",
    "}\n",
    "\n",
    "train_generator = TextDataGenerator(x_vector, y_vector, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1663662046539,
     "user": {
      "displayName": "Felix Stockhammer (Stocki198)",
      "userId": "00639432236174564081"
     },
     "user_tz": -120
    },
    "id": "5zxgM6Uv_DHt",
    "outputId": "7b3b79ec-1e1d-4b23-eeb7-51b3342a25a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 25002\n",
      "Number of Sequences: 10315059\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Vocabulary: {}\".format(VOCAB_SIZE))\n",
    "print(\"Number of Sequences: {}\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Objects to use in the next notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyXsaidog88F"
   },
   "outputs": [],
   "source": [
    "# Saving relevant objects for applying the model\n",
    "import pickle\n",
    "with open('./data/objs.pkl', 'wb') as f:\n",
    "    pickle.dump([c, dictionary, index_to_word, word_to_index, SEQ_LENGTH, VOCAB_SIZE, BATCH_SIZE], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEbCpkY4HnPV"
   },
   "outputs": [],
   "source": [
    "# saving relevant objects for training the model\n",
    "with open('./data/objs_rel.pkl', 'wb') as f:\n",
    "    pickle.dump([SEQ_LENGTH, VOCAB_SIZE, train_generator], f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "3174b81f-1ca2-4cc7-8a6b-69ad39b69929",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
