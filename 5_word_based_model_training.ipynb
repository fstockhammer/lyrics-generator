{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "657db6d5-17d0-4811-9a01-cb012c63d6bf",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "id": "jehXeXNHmclc",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# 5. Word-Based Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOfrhR-9bFfh"
   },
   "source": [
    "In this notebook, the lyrics will be used to train a model that learns how to write song lyrics.<br>\n",
    "__Note:__ Recommended to train on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00001-985082fc-d61d-4aca-812e-7b9c3c7e2211",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 2973,
     "status": "ok",
     "timestamp": 1662374116505,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "execution_millis": 3,
    "execution_start": 1656422208266,
    "id": "LL9i5KbCmclg",
    "source_hash": "b4788a64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1662374119595,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "id": "zMQCrusVCo8M",
    "outputId": "33a98670-2804-4e21-8083-9d8ecfce5866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# check connection to gpu\n",
    "print('Found GPU at: {}'.format(tf.test.gpu_device_name()))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1662374119595,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "id": "Tn92LSEHJSjV"
   },
   "outputs": [],
   "source": [
    "# create class for fitting to a sequence of data\n",
    "# useful for multiprocessing\n",
    "class TextDataGenerator(Sequence):\n",
    "    def __init__(self, sequences, next_words, sequence_length, vocab_size, batch_size=32, shuffle=True, embedding=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.sequences = sequences\n",
    "        self.next_words = next_words\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.shuffle = shuffle\n",
    "        self.embedding = embedding\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # must be implemented for class Sequence\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.sequences) / self.batch_size))\n",
    "\n",
    "    # must be implemented for class Sequence, gets batch at position index\n",
    "    def __getitem__(self, index):\n",
    "        # take sample of indexes, length = batch_size\n",
    "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        # store relevant x and y data\n",
    "        sequences_batch = [self.sequences[k] for k in indexes]\n",
    "        next_words_batch = [self.next_words[k] for k in indexes]\n",
    "\n",
    "        if self.embedding:\n",
    "          X = np.array(sequences_batch)\n",
    "          y = keras.utils.to_categorical(next_words_batch, num_classes=self.vocab_size)\n",
    "        else:\n",
    "          X, y = self.__data_generation(sequences_batch, next_words_batch)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.sequences)) # vector of length len(x_data)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, sequences_batch, next_words_batch):\n",
    "        # create empty, 3 dimensional matrices\n",
    "        X = np.zeros((self.batch_size, self.sequence_length, self.vocab_size), dtype=bool)\n",
    "        y = np.zeros((self.batch_size, self.vocab_size), dtype=bool)\n",
    "\n",
    "        # fill matrices with 1 at the position of the word, essentially one-hot encoding\n",
    "        for i, seq in enumerate(sequences_batch):\n",
    "            for j, word in enumerate(seq):\n",
    "                X[i, j, word] = 1\n",
    "                y[i, next_words_batch[i]] = 1\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 29202,
     "status": "ok",
     "timestamp": 1662374148794,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "id": "leCTQey_Iahr"
   },
   "outputs": [],
   "source": [
    "# Loading relevant objects:\n",
    "with open('./data/objs_rel.pkl','rb') as f:\n",
    "    SEQ_LENGTH, VOCAB_SIZE, train_generator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1662374148795,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "id": "vz0LHvLAPXHI"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"callbacks_model/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nWX0fqJiEWh"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCER0JuhiVlo"
   },
   "source": [
    "We are using a sequential model that works with a LSTM architecture that works well with sequential data such as our song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00020-536bd844-f126-4f95-bf0c-efa2b4bdb2af",
    "deepnote_cell_height": 171,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1662374148795,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "execution_millis": 6872,
    "execution_start": 1656422224888,
    "id": "w46MWRzsmclp",
    "source_hash": "1298be53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1662374150136,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "id": "7Hyk9sn6pGqY",
    "outputId": "fc281ce6-ecb1-4af2-f910-a6f0a491ad79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               12867072  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25002)             3225258   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 25002)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,092,330\n",
      "Trainable params: 16,092,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = (SEQ_LENGTH, VOCAB_SIZE)))\n",
    "model.add(Dense(VOCAB_SIZE))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1662374150137,
     "user": {
      "displayName": "Lumos Songwriter",
      "userId": "10320565956419339651"
     },
     "user_tz": -120
    },
    "id": "kQlDuU60p3sH"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', run_eagerly = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00022-3204a537-ff89-4501-a741-f3c38ef336df",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 334.578125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     174.796875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 608,
    "execution_start": 1656422713506,
    "id": "y5Jq-hsumclq",
    "outputId": "7675970e-3767-451f-d84b-a6b08f5294cd",
    "owner_user_id": "0521d975-2628-4a52-9df2-cf8d9db8da1f",
    "source_hash": "2e725d63",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "158751/158751 [==============================] - ETA: 0s - loss: 4.4731\n",
      "Epoch 3: saving model to callbacks_model_5/cp.ckpt\n",
      "158751/158751 [==============================] - 7938s 50ms/step - loss: 4.4731\n",
      "Epoch 4/5\n",
      "158750/158751 [============================>.] - ETA: 0s - loss: 4.1206\n",
      "Epoch 4: saving model to callbacks_model_5/cp.ckpt\n",
      "158751/158751 [==============================] - 7933s 50ms/step - loss: 4.1206\n",
      "Epoch 5/5\n",
      "119601/158751 [=====================>........] - ETA: 32:49 - loss: 4.0070"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, \n",
    "          epochs = 5,\n",
    "          initial_epoch=1,\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNqFkYdLBjos"
   },
   "source": [
    "__Ressource for explaining Dropout:__ https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf <br>\n",
    "__Model Architecture:__ https://www.analyticsvidhya.com/blog/2018/03/text-generation-using-python-nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eauW7RyMpR--"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'model.h5'\n",
    "model.save(filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "3174b81f-1ca2-4cc7-8a6b-69ad39b69929",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
